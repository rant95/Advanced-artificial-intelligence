{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RCP211 RL TP2_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIMEBv53g-o6"
      },
      "source": [
        "# Model Free Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8UwOAGTgz6H"
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from time import sleep\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "import numpy.matlib\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiGoZv3_hMps"
      },
      "source": [
        "## Marche aléatoire\n",
        "\n",
        "Dans cet exemple simple, nous essayons d'évaluer la fonction de valeur des états correspondant à un problème de marche aléatoire. Ici, l'agent suit une politique aléatoire et peut aller soit à gauche avec une probabilité $p$ soit à droite avec une probabilité $1-p$. Il existe en tout $N$ cases sur lesquelles l'agent peut se déplacer ainsi que deux cases terminales d'où il ne peut pas repartir : \n",
        "\n",
        "$$ \\square \\overset{0}{\\leftarrow} 1 \\overset{0}{\\longleftrightarrow} \\cdots \\overset{0}{\\longleftrightarrow} N \\overset{1}{\\rightarrow} \\blacksquare $$\n",
        "\n",
        "La récompense de passer d'un état à l'autre est nul exceptée pour la terminaison de droite.\n",
        "\n",
        "### Dynamic programming \n",
        "\n",
        "Ce problème est suffisament simple pour pouvoir êêtre calculé à la main (*cf.* cours). Ceci nous permettra dans ce cas de vérifier l'estimation obtenue. \n",
        "\n",
        "### First Visit Monte Carlo \n",
        "\n",
        "Une première façon d'estimer la fonction de valeur en chaque état est de générer plusieurs marches aléatoires en gardant en mémoire combien de fois les états ont été visités et pour quel valeur de retour. La moyenne du retour pour chaque état nous donne ainsi une estimation non biaisée de la fonction de valeur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGzlgMr8G6R-"
      },
      "source": [
        "La fonction suivante donne le retour et le nombre de fois qu'un état à été visité (first-visite)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LijUtVfXhQJL"
      },
      "source": [
        "def MC_random_walk(i0,N):\n",
        "  Ns = np.zeros([N,1])\n",
        "  i = i0\n",
        "  G = np.zeros([N,1])\n",
        "  Ns[i] = 1\n",
        "  while i!=-1 and i!=N:\n",
        "    pi = np.random.binomial(1, .5, 1)\n",
        "    i = i+1 if pi==0 else i-1\n",
        "    if i in range(N) and Ns[i]==0:\n",
        "      Ns[i] = 1\n",
        "    elif i==N:\n",
        "      G[np.argwhere(Ns==1)[:,0]] = 1\n",
        "  return Ns, G"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zKss32-HHWZ"
      },
      "source": [
        "#### Coding Task\n",
        "\n",
        "Complétez le code suivant pour permettre l'estimation de la fonction d'état"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os7aZIGPsbwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e3bddb-77d5-4d21-e176-40a445b340b6"
      },
      "source": [
        "iter = 1000\n",
        "Nb_states = 5\n",
        "Ns = np.zeros([N,1])\n",
        "G  = 0\n",
        "for i in range(iter):\n",
        "  MC_est = MC_random_walk(3,Nb_states)\n",
        "  Ns = Ns + MC_est[0]\n",
        "  G  = G  + MC_est[1]\n",
        "\n",
        "V = G/Ns\n",
        "V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15696203],\n",
              "       [0.3313253 ],\n",
              "       [0.50812408],\n",
              "       [0.667     ],\n",
              "       [0.83375   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE68Rrc7j9Vi"
      },
      "source": [
        "### Temporal Difference-Learning\n",
        "\n",
        "Plutôt que d'estimer le retour après chaque trajectoire, nous allons mettre à jour l'estimation de la fonction de valeur dès qu'un état est visité en s'appuyant sur l'équation de Bellman :\n",
        "\n",
        "$$ V(S_t ) \\leftarrow V(S_t) + \\alpha\\left[R_{t+1} + \\gamma V(S_{t+1}) - V(S_t) \\right] $$\n",
        "\n",
        "Ici, nous prendrons les discount factors $\\gamma$ et $\\alpha$ égaux à 1 . \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3AVTIGkHO4B"
      },
      "source": [
        "#### Coding Task :\n",
        "\n",
        "Complétez la fonction suivant pour l'estimation de la valeur pendant que l'agent évalue dans son environnement avec l'algorithme TD0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygi28-HhmfYZ"
      },
      "source": [
        "N = 5\n",
        "def TD0_random_walk(V,i0,alpha,gamma):\n",
        "  i = i0\n",
        "  i_old = i0\n",
        "  R = 0\n",
        "  while i!=-1 and i!=N:\n",
        "    pi = np.random.binomial(1, .5, 1)\n",
        "    i = i+1 if pi==0 else i-1\n",
        "    if i==N:\n",
        "      R = 1\n",
        "      V[i_old] = V[i_old] + alpha*(R + 0 - V[i_old])\n",
        "    elif i==-1:\n",
        "      V[i_old] = V[i_old] + alpha*(R + 0 - V[i_old])\n",
        "    else:\n",
        "      V[i_old] = V[i_old] + alpha*(R + gamma*V[i] - V[i_old])\n",
        "    #print((i_old,i))\n",
        "    i_old = i\n",
        "  return V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I1ZP_KwHdas"
      },
      "source": [
        "Itérons un certain nombre d'epochs pour avoir une bonne estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI9gNF4ipYYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cd8a5a-dc9b-4bb6-e02d-01842dffecd9"
      },
      "source": [
        "iter = 1000\n",
        "V = np.zeros([N,1])\n",
        "\n",
        "for i in range(iter):\n",
        "  V = TD0_random_walk(V,3,.05,1)\n",
        "  \n",
        "print(V)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.15553234]\n",
            " [0.32566813]\n",
            " [0.5378693 ]\n",
            " [0.701708  ]\n",
            " [0.84790211]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCSM-ojovQW-"
      },
      "source": [
        "### Forward-View TD($\\lambda$)\n",
        "\n",
        "Plutôt que n'utiliser que le prochain état pour mettre à jour l'estimation de l'état courrant, Il peut être tentant de voir plus loin dans le futur pour estimer la valeur d'être dans un état particulier. L'algorithme Forward-View TD($\\lambda$) permet de combiner l'ensemble des estimations pouvant être faites en utilisant l'information provenant d'un, deux, trois, etc réalisations future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4W4ojGKp70i"
      },
      "source": [
        "def FVTD_lambda_random_walk(V,i0,lambda_,alpha,gamma):\n",
        "  V_new = V.copy() # Offline updates\n",
        "  i = i0\n",
        "  i_old = i\n",
        "  R = 0\n",
        "  mooves = []\n",
        "  Gt_lambda = np.zeros([N,1])\n",
        "  while i!=-1 and i!=N:\n",
        "    pi = np.random.binomial(1, .5, 1)\n",
        "    i = i+1 if pi==0 else i-1\n",
        "    R = 0 if i!=N else 1\n",
        "    mooves.append((i_old,i,R)) # position en t, postition en t+1, récompense immédiate \n",
        "    i_old = i\n",
        "\n",
        "  for t in range(len(mooves)):\n",
        "    Gn_array = []\n",
        "    R_sum = 0\n",
        "    i = mooves[t][0]\n",
        "    for n, m in enumerate(mooves[t:]):\n",
        "      now, next, R = m\n",
        "      R_sum += gamma**n*R\n",
        "      Gn_t = lambda_**n*R_sum if next==N or next==-1 else lambda_**n*(R_sum + V[next])\n",
        "      Gn_array.append(Gn_t)\n",
        "    Glambda_t = (1-lambda_)*sum(Gn_array[:-1]) + Gn_array[-1]\n",
        "    if i in range(N):\n",
        "      V_new[i] = V[i] + alpha*(Glambda_t - V[i])\n",
        "    #print(f' moove t = {mooves[t]}, \\n Gn_array = {Gn_array}, \\n Glambda_t = {Glambda_t}, \\n V = {V_new}, \\n')\n",
        "  return V_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ed8-oDtFlTF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "306cdd7b-1605-4fdc-851d-8cd09378fd2b"
      },
      "source": [
        "iter = 10000\n",
        "V = 0*np.ones([N,1])\n",
        "\n",
        "for i in range(iter):\n",
        "  V = FVTD_lambda_random_walk(V,2,1,.1,1)\n",
        "print(V)\n",
        "Vt = [1/6,2/6,3/6,4/6,5/6]\n",
        "print(f'RMSE = {np.sqrt(np.mean( (V - Vt)**2 ))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.09994937]\n",
            " [0.28164025]\n",
            " [0.55402685]\n",
            " [0.80292355]\n",
            " [0.95034747]]\n",
            "RMSE = 0.3957255827604822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZD3Ap-Vls8w"
      },
      "source": [
        "### Backward View TD($\\lambda$)\n",
        "\n",
        "L'algorithme forward view TD($\\lambda$) ne peut pas produire une estimation *online*, c'est à dire qu'il faut attendre que l'agent ait terminé sa trajectoire pour pouvoir avoir un échantillon et mettre à jour la fonction de valeur. Une variante permettant de résoudre ce problème est l'algorithme Backward View TD($\\lambda$). Celui-ci garde en mémoire le nombre de passages par un état pour calculer l'erreur et mettre à jour la fonction de valeur pour l'état visité."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgi0LMEGG5Aj"
      },
      "source": [
        "def BVTD_lambda_random_walk(V,i0,lambda_,gamma,alpha):\n",
        "  V_new = V.copy() # Offline updates\n",
        "  E = np.zeros([N,1])\n",
        "  i = i0\n",
        "  i_old = i\n",
        "  R = 0\n",
        "  while i!=-1 and i!=N:\n",
        "    E = gamma*lambda_*E\n",
        "    E[i] += 1\n",
        "    pi = np.random.binomial(1, .5, 1)\n",
        "    i = i+1 if pi==0 else i-1 # next state\n",
        "    R = 0 if i!=N else 1\n",
        "    delta = R - V[i_old] if i==-1 or i==N else R + gamma*V[i] - V[i_old]\n",
        "    V_new[i_old] += alpha*delta*E[i_old]\n",
        "    #print(f' moove t = {(i_old,i)}, \\n E = {E}, \\n V = {V_new}, \\n')\n",
        "    i_old = i\n",
        "  return V_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMjTj13TXTe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "91b2eb36-70e2-447c-fc8e-01c6fe67ccb1"
      },
      "source": [
        "iter = 1000\n",
        "V = np.zeros([N,1])\n",
        "\n",
        "for i in range(iter):\n",
        "  V = BVTD_lambda_random_walk(V,3,.5,1,.1)\n",
        "  \n",
        "print(V)\n",
        "Vt = [1/6,2/6,3/6,4/6,5/6]\n",
        "print(f'RMSE = {np.sqrt(np.mean( (V - Vt)**2 ))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.13480436]\n",
            " [0.32925962]\n",
            " [0.49520147]\n",
            " [0.70934396]\n",
            " [0.88949826]]\n",
            "RMSE = 0.35661035366915894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93fNH2MiPdaT"
      },
      "source": [
        "## Model Free Control\n",
        "\n",
        "Pour l'instant nous avons vu deux approches Monte Carlo et TD pour estimer la fonction de valeur d'un MDP. À présent nous allons voir comment faire du contrôle, c'est à dire trouver la meilleur politique.\n",
        "\n",
        "Lorsque le contrôle était basé sur un model, nous avons vu queune façon efficace d'estimer la politique optimale était de faire une sélection gloutonne parmis les actions pour sélectioner celles qui maximiseront la fonction de valeur. Ici, nous n'avons plus de modèle ce qui veut dire que nous n'avons pas accès aux propabilités de transitions - ou alors que nous ne nous souhaitons pas nous en préocuper. Il ne nous est donc plus possible d'être exhaustif dans le choix de nos actions et plutôt que d'estimer la fonction de valeur du MDP, nous allons estimer sa fonction d'action-valeur $Q(s,a)$ ce qui nous affranchi de devoir connaitre explicitement les transitions.\n",
        "\n",
        "### GLIE Monte Carlo control\n",
        "\n",
        "Une première façon simple d'estimer $Q(s,a)$ est d'utiliser un échantillonnage par Monte Carlo. Pour chaque paire d'état, actions $(s,a)$ visitée, nous incrémentons un compteur et nous lui associons le retour obtenu pour une certaine trajectoire. La valeur $Q(s,a)$ est ensuite obtenue en moyennant les différents retours pour toutes les trajectoires de l'agent.\n",
        "\n",
        "La politique optimale est ensuite obtenue en sélectionnant de façon gloutonne l'action qui va maximiser $Q$. Pour s'assurer d'explorer tout l'espace des états et actions et converger ainsi vers la politique optimale, la politique est parfois choisie de manière aléatoire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "SSDXeHb746V8"
      },
      "source": [
        "#@title GridWorld Class \n",
        "\n",
        "class GridWorld:\n",
        "  def __init__(self, size=(5,5), start=[2,0], end=[4,2],r=-1):\n",
        "    self.size = size\n",
        "    self.Nx, self.Ny = size\n",
        "    self.start = start\n",
        "    self.state = start\n",
        "    self.end = end\n",
        "    self.EOG = 0\n",
        "    self.actions = ('E','N','W','S')\n",
        "    self.r = r\n",
        "\n",
        "  def reboot(self):\n",
        "    self.state = self.start\n",
        "    self.EOG = 0\n",
        "    \n",
        "  def go(self,action):\n",
        "    s = self.state.copy()\n",
        "    if not action in self.actions:\n",
        "      raise ValueError('Action should be one of the following : E, N, W or S')\n",
        "    elif action=='N' and s[1] < self.Ny-1:\n",
        "      s[1] += 1\n",
        "    elif action=='S' and s[1] > 0:\n",
        "      s[1] -= 1\n",
        "    elif action=='E' and s[0] < self.Nx-1:\n",
        "      s[0] += 1\n",
        "    elif action=='W' and s[0] > 0:\n",
        "      s[0] -= 1\n",
        "    self.state = s\n",
        "    if s == self.end:\n",
        "      self.EOG = 1\n",
        "      r = 0\n",
        "    else:\n",
        "      r = self.r\n",
        "    return r\n",
        "\n",
        "  def plot_grid(self):\n",
        "    grid = np.zeros([self.Nx,self.Ny])\n",
        "    x,y = self.end\n",
        "    grid[self.Ny-y-1,x] = -1\n",
        "    x,y = self.state\n",
        "    grid[self.Ny-y-1,x] = 1\n",
        "    plt.imshow(grid)\n",
        "    plt.show()\n",
        "    sleep(1)\n",
        "    clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "N2YIHXb35Btd"
      },
      "source": [
        "#@title ActionState Class\n",
        "\n",
        "class ActionStateTable:\n",
        "  def __init__(self,size,values=0,end=[4,2]):\n",
        "    self.Nx, self.Ny = size\n",
        "    self.Ns = self.Nx*self.Ny\n",
        "    self.actions = ('E','N','W','S')\n",
        "    self.Na = len(self.actions)\n",
        "    self.values = np.full(shape=[self.Ns,self.Na],fill_value=values)\n",
        "    self.end = end\n",
        "\n",
        "  def get(self,s,a):\n",
        "    x,y = s\n",
        "    ia = np.argwhere([i==a for i in self.actions])\n",
        "    return self.values[x*self.Ny + y,ia]\n",
        "\n",
        "  def update(self,s,a,d): # s : (0,0),...,(0,Ny-1),...,(Nx-1,Ny-1) & a : E,N,W,S\n",
        "    x,y = s\n",
        "    #print(f's = {s}')\n",
        "    ia = np.argwhere([i==a for i in self.actions])\n",
        "    self.values[x*self.Ny + y, ia] = d\n",
        "\n",
        "  def greedy(self,s):\n",
        "    x,y = s\n",
        "    ia = np.argmax(self.values[x*self.Ny + y, :])\n",
        "    return self.actions[ia]\n",
        "\n",
        "  def plot_table(self):\n",
        "    plt.xticks(np.arange(-1, self.Nx+1, 1))\n",
        "    plt.yticks(np.arange(-1, self.Ny+1, 1))\n",
        "    plt.grid( which='major')\n",
        "\n",
        "    param = {'lw':3,\n",
        "            'head_width':1/(self.Nx+self.Ny)}\n",
        "    for i in range(self.Ns):\n",
        "      ll = self.values[i,:]\n",
        "      y = i%self.Ny\n",
        "      x = math.floor(i/self.Ny)\n",
        "      if [x,y] == self.end:\n",
        "        continue\n",
        "      n = np.argmax(ll)\n",
        "      if n==0:\n",
        "        plt.arrow(x,y,.5,0,**param)\n",
        "      elif n==1:\n",
        "        plt.arrow(x,y,0,.5,**param)\n",
        "      elif n==2:\n",
        "        plt.arrow(x,y,-.5,0,**param)\n",
        "      elif n==3:\n",
        "        plt.arrow(x,y,0,-.5,**param)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "M3F2ky8rDhvQ"
      },
      "source": [
        "#@title Trajectory Class\n",
        "\n",
        "class Trajectory:\n",
        "  def __init__(self,grid,gamma=1,show=0,T=1e3):\n",
        "    self.grid = grid\n",
        "    self.G = 0\n",
        "    self.gamma = gamma\n",
        "    self.actions = grid.actions\n",
        "    self.show = show\n",
        "    self.T = T\n",
        "\n",
        "  def get_action(self,Q,s,epsilon):\n",
        "    pi = np.random.binomial(1, epsilon, 1)\n",
        "    available_actions = list(self.actions)\n",
        "    if s[0] == 0:\n",
        "      available_actions.remove('E')\n",
        "    if s[0] == self.grid.Nx-1:\n",
        "      available_actions.remove('W')\n",
        "    if s[1] == 0:\n",
        "      available_actions.remove('S')\n",
        "    if s[1] == self.grid.Ny-1:\n",
        "      available_actions.remove('N')\n",
        "    if pi==0:\n",
        "      a = Q.greedy(s)\n",
        "    else:\n",
        "      a = random.choice(available_actions)\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvptPsqHEl1H"
      },
      "source": [
        "Pour commencer nous allons implémenter la version Monte-Carlo du contrôle. La fonction suivante permet de lancer une trajectoire et donne en sortie le retour et le nombre de fois qu'un état à été visité."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkvL3r5tVnGn"
      },
      "source": [
        "def MC_run(traj,Q,epsilon):\n",
        "  grid = traj.grid\n",
        "  size = grid.size\n",
        "  N = ActionStateTable(size=size)\n",
        "  G = ActionStateTable(size=size)\n",
        "  r = 0\n",
        "  t = 0\n",
        "  grid.reboot()\n",
        "  while not grid.EOG and t<traj.T:\n",
        "    if traj.show:\n",
        "      traj.grid.plot_grid()\n",
        "    s = grid.state\n",
        "    a = traj.get_action(Q,s,epsilon)\n",
        "    #print(f'action is {a}')\n",
        "    r += grid.go(a)\n",
        "    N.update(s,a,1)\n",
        "    G.update(s,a,r)\n",
        "    t+=1\n",
        "  return G, N\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GhOeGwPFOTy"
      },
      "source": [
        "### Coding task :\n",
        "\n",
        "Compléter le code suivant pour mettre à jour la Q table ainsi $\\epsilon$ de façon à converger vers une politique optimale. On dera une mise à jour touts les 10 trajectoires."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-zhKIg7DCxa"
      },
      "source": [
        "grid = GridWorld()\n",
        "traj = Trajectory(grid,show=0,T=2000)\n",
        "Q = ActionStateTable(size=grid.size,values=-1e3)\n",
        "G = ActionStateTable(size=grid.size,values=-1e3)\n",
        "N = ActionStateTable(size=grid.size,values=1)\n",
        "iter = 5000\n",
        "update_every = 10\n",
        "epsilon = 1\n",
        "alpha = .9\n",
        "for i in range(iter):\n",
        "  Gi,Ni = MC_run(traj,Q,epsilon)\n",
        "  G.values += Gi.values\n",
        "  N.values += Ni.values\n",
        "  if i%update_every==update_every-1:\n",
        "    print(f'iter {i}/{iter}')\n",
        "    Q.values = G.values/N.values\n",
        "    epsilon = epsilon*0.96\n",
        "    print(f'epsilon = {epsilon}')\n",
        "  if i == iter-10:\n",
        "    traj.show = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1ZyMckFmrb"
      },
      "source": [
        "Affichons les actions sur la grille pour observer si le comportement de l'agent permet d'atteindre le but recherché (à défaut d'être réellement optimal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ZQ26fBfK88qV",
        "outputId": "1a88a473-83fd-4144-b3d4-b7f881ff678f"
      },
      "source": [
        "Q.plot_table()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmWtTcI6FzrL"
      },
      "source": [
        "### Coding task\n",
        "\n",
        "A présent, complétez la fonction suivante pour permettre le contrôle avec l'algorithme SARSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k1VsoSeE0Op"
      },
      "source": [
        "\n",
        "def SARSA_run(traj,Q,alpha,epsilon):\n",
        "  grid = traj.grid\n",
        "  size = grid.size\n",
        "  grid.reboot()\n",
        "  s0 = grid.state\n",
        "  a0 = traj.get_action(Q,s0,epsilon)\n",
        "  q0 = Q.get(s0,a0)\n",
        "  t = 0\n",
        "  err = 0\n",
        "  while not grid.EOG and t<traj.T:\n",
        "    if traj.show:\n",
        "      traj.grid.plot_grid()\n",
        "    r = grid.go(a0)\n",
        "    s1 = grid.state\n",
        "    a1 = traj.get_action(Q,s1,epsilon)\n",
        "    q1 = Q.get(s1,a1)\n",
        "    delta = r + traj.gamma*q1 - q0\n",
        "    delta = min(1e2,delta) # clipping the TD error to avoid exploding gradient like phenomenon\n",
        "    err += delta\n",
        "    d = Q.get(s0,a0) + alpha*delta\n",
        "    Q.update(s0,a0,np.squeeze(d))\n",
        "    a0 = a1\n",
        "    s0 = s1\n",
        "    t+=1\n",
        "  return Q, err/(t-1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxkaz0TSF_PV"
      },
      "source": [
        "L'entraînement est légèrement différent (et plus simple) qu'avec l'approche MC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX-P_JwxRK9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "59c7b618-1c4d-4db5-c6bc-026bc0870a20"
      },
      "source": [
        "grid = GridWorld(start=[2,0],end=[2,4],r=-1e3)\n",
        "traj = Trajectory(grid,show=0,T=1000)\n",
        "Q = ActionStateTable(size=grid.size,values=0.,end=[2,4])\n",
        "iter = 1000\n",
        "update_every = 10\n",
        "epsilon = 1\n",
        "alpha = 1e-2\n",
        "for i in range(iter):\n",
        "  Q, err = traj.SARSA_run(Q,alpha,epsilon)\n",
        "  if i%update_every==update_every-1:\n",
        "    print(f'iter {i}/{iter} , mean delta : {err/update_every}')\n",
        "    epsilon = epsilon*0.96\n",
        "    print(f'epsilon = {epsilon}')\n",
        "  if i == iter-10:\n",
        "    traj.show = 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-5b9e9ed0ca19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSARSA_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mupdate_every\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mupdate_every\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'iter {i}/{iter} , mean delta : {err/update_every}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-134-efda3da0e638>\u001b[0m in \u001b[0;36mSARSA_run\u001b[0;34m(self, Q, alpha, epsilon)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEOG\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m       \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-134-efda3da0e638>\u001b[0m in \u001b[0;36mplot_grid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPtT9MycGMOp"
      },
      "source": [
        "Observons la politique à présent. Vous pouvez tester différentes configuration en faisant varier le point de départ et d'arriver dans le gridworld correspondant aux paramètres `start` et `end`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM6l2uZc9yQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "2d8a30c7-835f-43fd-9df0-d4d51cc44498"
      },
      "source": [
        "Q.plot_table()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78yXs5lGZXK"
      },
      "source": [
        "### Coding task\n",
        "\n",
        "Complétez la fonction suivante correspondant à une trajectoire avec mise à jour de la valeur suivant l'algorithme Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW5xE0D8Y-8k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c287dbb8-39d2-4cdd-f9a1-c7182b1767f3"
      },
      "source": [
        "def QLearning_run(traj,Q,alpha,epsilon):\n",
        "  grid = traj.grid\n",
        "  size = grid.size\n",
        "  grid.reboot()\n",
        "  t = 0\n",
        "  err = 0\n",
        "  s0 = grid.state\n",
        "  while not grid.EOG and t<traj.T:\n",
        "    if traj.show:\n",
        "      traj.grid.plot_grid()\n",
        "    a0 = traj.get_action(Q,s0,epsilon)\n",
        "    q0 = Q.get(s0,a0)\n",
        "    r = grid.go(a0)\n",
        "    s1 = grid.state\n",
        "    a1 = traj.get_action(Q,s1,0)\n",
        "    q1 = Q.get(s1,a1)\n",
        "    delta = r + traj.gamma*q1 - q0\n",
        "    delta = min(1e2,delta) # clipping the TD error to avoid exploding gradient like phenomenon\n",
        "    err += delta\n",
        "    d = Q.get(s0,a0) + alpha*delta\n",
        "    Q.update(s0,a0,np.squeeze(d))\n",
        "    s0 = s1\n",
        "    t+=1\n",
        "  return Q, err/(t-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMBsZjWbGv-J"
      },
      "source": [
        "Procédons enfin à l'entraîenemt avant d'observer la politique de l'agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j4BQdnTGspU"
      },
      "source": [
        "grid = GridWorld(start=[2,0],end=[2,4],r=-1e3)\n",
        "traj = Trajectory(grid,show=0,T=1000)\n",
        "Q = ActionStateTable(size=grid.size,values=0.,end=[2,4])\n",
        "iter = 1000\n",
        "update_every = 10\n",
        "epsilon = 1\n",
        "alpha = 1e-2\n",
        "for i in range(iter):\n",
        "  Q, err = traj.QLearning_run(Q,alpha,epsilon)\n",
        "  if i%update_every==update_every-1:\n",
        "    print(f'iter {i}/{iter} , mean delta : {err/update_every}')\n",
        "    epsilon = epsilon*0.96\n",
        "    print(f'epsilon = {epsilon}')\n",
        "  if i == iter-10:\n",
        "    traj.show = 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}