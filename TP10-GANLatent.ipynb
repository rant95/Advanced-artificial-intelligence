{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd6ee05",
   "metadata": {},
   "source": [
    "\n",
    "<a id='chap-tpganlatent'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923c9df5",
   "metadata": {},
   "source": [
    "# Travaux pratiques : espace latent des GAN\n",
    "\n",
    "Cette séance de travaux pratiques sert d’illustration à l’exploration\n",
    "d’un espace latent et à l’évaluation des modèles génératifs. L’objectif\n",
    "est de mieux comprendre comment manipuler et interpréter les codes\n",
    "latents.\n",
    "\n",
    "Pour cette séance, nous allons utiliser le jeu de données de chiffres\n",
    "manuscrits MNIST mais les méthodes étudiées s’adaptent à n’importe quel\n",
    "ensemble d’observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c57f49e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Dernière version de torchvision pour MNIST\n",
    "%pip install -U torchvision\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c12bd6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63edeb9c",
   "metadata": {},
   "source": [
    "## Qualité de la distribution apprise\n",
    "\n",
    "Pour gagner du temps, nous allons récupérer des modèles préentraînés sur\n",
    "MNIST. En particulier nous allons réutiliser un générateur de DCGAN\n",
    "(*Deep Convolutional GAN*) entraîné sur MNIST, ainsi qu’une classifieur\n",
    "entraîné sur les observations d’apprentissage.\n",
    "\n",
    "*Note* : ces modèles ont été mis à disposition par [Chandan\n",
    "Singh](https://github.com/csinva/gan-vae-pretrained-pytorch),\n",
    "doctorant à UC Berkeley."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe7962",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Téléchargement des fichiers de poids\n",
    "!wget -nc https://raw.githubusercontent.com/csinva/gan-vae-pretrained-pytorch/master/mnist_dcgan/weights/netG_epoch_99.pth\n",
    "!wget -nc https://raw.githubusercontent.com/csinva/gan-vae-pretrained-pytorch/master/mnist_classifier/weights/lenet_epoch%3D12_test_acc%3D0.991.pth -O lenet.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa4b95",
   "metadata": {},
   "source": [
    "Le classifieur est une architecture convolutive simple dite « LeNet5 ».\n",
    "Le code ci-dessous permet de construire un tel modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4511b3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.convnet = nn.Sequential(OrderedDict([\n",
    "            ('c1', nn.Conv2d(1, 6, kernel_size=(5, 5))),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('s2', nn.MaxPool2d(kernel_size=(2, 2), stride=2)),\n",
    "            ('c3', nn.Conv2d(6, 16, kernel_size=(5, 5))),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('s4', nn.MaxPool2d(kernel_size=(2, 2), stride=2)),\n",
    "            ('c5', nn.Conv2d(16, 120, kernel_size=(5, 5))),\n",
    "            ('relu5', nn.ReLU()),\n",
    "            ('flatten', nn.Flatten())\n",
    "        ]))\n",
    "\n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('f6', nn.Linear(120, 84)),\n",
    "            ('relu6', nn.ReLU()),\n",
    "            ('f7', nn.Linear(84, 10)),\n",
    "            ('sig7', nn.LogSoftmax(dim=-1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.convnet(img)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "lenet = LeNet5().eval()\n",
    "lenet.load_state_dict(torch.load('lenet.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801f74f",
   "metadata": {},
   "source": [
    "Le générateur est un réseau convolutif à 5 couches. La dimension de\n",
    "l’espace latent de ce modèle préappris est de 100. Les codes $ z $\n",
    "ont été échantillonnés lors de l’apprentissage selon une loi normale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956422a3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, out_channels=1, latent_dim=100, n_planes=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # Le code Z est déconvolué\n",
    "            nn.ConvTranspose2d(latent_dim, n_planes * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(n_planes * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Activations (n_planes*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(n_planes * 8, n_planes * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_planes * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Activations (n_planes*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(n_planes * 4, n_planes * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_planes * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Activations (n_planes*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(n_planes * 2, n_planes, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(n_planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(n_planes, out_channels, kernel_size=1, stride=1, padding=2, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.unsqueeze(-1).unsqueeze(-1)\n",
    "        output = self.main(input)\n",
    "        return output\n",
    "\n",
    "G = Generator().eval()\n",
    "G.load_state_dict(torch.load('netG_epoch_99.pth'), map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346a451",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "En utilisant le générateur, écrivez une fonction `code2image` qui\n",
    "prend en entrée un ou plusieurs codes `z` (de dimensions\n",
    "$ (n, 100, 1, 1) $) et renvoie un tenseur d’autant d’images (de\n",
    "dimensions $ (n, h, w) $). Générez et affichez quelques images de\n",
    "chiffres manuscrits synthétiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221def8c",
   "metadata": {},
   "source": [
    "## Correction\n",
    "\n",
    "La fonction de conversion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b9178",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def code2image(code):\n",
    "    z = torch.Tensor(code)\n",
    "    with torch.no_grad():\n",
    "        image = G(z)\n",
    "    return np.array(image[0,0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2080e1",
   "metadata": {},
   "source": [
    "Affichage des images :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d40645",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "z = torch.randn(10, 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(16, 2))\n",
    "for i, code in enumerate(codes):\n",
    "    image = code2image(code.unsqueeze(0))\n",
    "    fig.add_subplot(1, 10, i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "fig.suptitle(\"Images générées\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08c277",
   "metadata": {},
   "source": [
    "Dans cette section, nous souhaitons tout d’abord regarder la\n",
    "distribution des classes dans les chiffres synthétiques. Nous pouvons\n",
    "déjà regarder la distribution des classes dans la base d’images MNIST :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c5687",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "mnist = MNIST(root=\"./mnist\", train=True, download=True)\n",
    "true_labels = np.array([label for _, label in mnist], dtype=int)\n",
    "\n",
    "# Calcul du nombre d'occurrences de chaque valeur\n",
    "occurrences = np.bincount(true_labels)\n",
    "\n",
    "for i, count in enumerate(occurrences):\n",
    "    plt.bar(i, count)\n",
    "plt.xticks(range(0, 10))\n",
    "plt.title(\"Nombre d'exemples par classe (MNIST)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c3f47a",
   "metadata": {},
   "source": [
    "Pour les données synthétiques produites par le générateur, nous n’avons\n",
    "pas l’information de la classe (le DCGAN utilisé pour générer ces\n",
    "observations n’est pas conditionnel). À défaut, nous pouvons toutefois\n",
    "utiliser un classifieur comme proxy pour étiqueter les images générées.\n",
    "\n",
    "Le modèle LeNet5 prend en entrée des images de taille\n",
    "$ 32\\times32 $. Il est donc nécessaire de redimensionner les images\n",
    "obtenues avec la fonction `code2image` qui produit des matrices\n",
    "$ 28\\times28 $. Vous pouvez utiliser la transformation ci-dessous à\n",
    "cette fin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd4383",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "resize = transforms.Resize(32)\n",
    "# Sur une image PIL\n",
    "print(\"-> Redimensionnement d'une image PIL\")\n",
    "print(mnist[0][0])\n",
    "print(resize(mnist[0][0]))\n",
    "# Sur un Tensor (dim n, w, h)\n",
    "print(\"-> Redimensionnement d'un tenseur PyTorch\")\n",
    "tensor = torch.Tensor(image).unsqueeze(0)\n",
    "print(tensor.shape)\n",
    "print(resize(tensor).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80def41e",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Échantillonnez 1000 codes dans l’espace latent. Pour chaque code,\n",
    "calculez l’image synthétique correspondante et utilisez LeNet5\n",
    "préentraîné pour obtenir la classe de chiffre associée. Affichez dans un\n",
    "histogramme le nombre d’occurrences de chaque classe de chiffres. Que\n",
    "constatez-vous ? Vérifiez si besoin avec les données réelles du jeu de\n",
    "données MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf184d49",
   "metadata": {},
   "source": [
    "## Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c63d2e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "n_codes = 10\n",
    "latent_dim = 100\n",
    "codes = torch.randn(n_codes, latent_dim)\n",
    "labels = np.zeros(n_codes, dtype=int)\n",
    "\n",
    "for idx, z in enumerate(tqdm(codes)):\n",
    "    image = G(z.reshape(1, latent_dim))\n",
    "    labels[idx] = torch.argmax(lenet(resize(image))).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38504754",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "occurrences = np.bincount(labels)\n",
    "\n",
    "for i, count in enumerate(occurrences):\n",
    "    plt.bar(i, count)\n",
    "plt.title(\"Nombre d'exemples par classe (images générées)\")\n",
    "plt.xticks(range(0, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e5981b",
   "metadata": {},
   "source": [
    "### Séparabilité des classes\n",
    "\n",
    "Une façon d’évaluer si le modèle reproduit correctement la structure de\n",
    "l’espace des données est considérer les frontières entre classes. Par\n",
    "exemple, les images correspondant au chiffre 0 générées par le GAN\n",
    "doivent se situer approximativement au même endroit dans l’espace des\n",
    "observations que les chiffres 0 réels.\n",
    "\n",
    "Pour mesurer cette propriété, une façon de faire est la suivante : -\n",
    "étiqueter (manuellement ou avec un classifieur) $ n $ images\n",
    "synthétiques - apprendre une SVM linéaire sur le jeu de données\n",
    "d’entraînement - évaluer cette SVM linéaire un jeu de données de test -\n",
    "évaluer la SVM linéaire sur les données synthétiques\n",
    "\n",
    "La SVM linéaire va trouver des hyperplans séparateurs dans l’espace des\n",
    "observations. Si le GAN conserve la structure de la distribution des\n",
    "données, alors ces hyperplans doivent également séparer les données\n",
    "synthétiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e4f9aa",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Appliquez cette méthode aux données ci-dessous. Que peut-on déduire des\n",
    "scores relatifs de la SVM sur le jeu de test réel et sur le jeu de test\n",
    "synthétique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc1780e",
   "metadata": {},
   "source": [
    "### Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f0946",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def to_np_dataset(mnist):\n",
    "    X, y = [], []\n",
    "    for data, label in mnist:\n",
    "        X.append(data.numpy().ravel())\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "train_mnist = MNIST(root=\"./mnist\", train=True, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "X_train, y_train = to_np_dataset(train_mnist)\n",
    "test_mnist = MNIST(root=\"./mnist\", train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5,), (0.5,)),\n",
    "                       ]))\n",
    "X_test, y_test = to_np_dataset(test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88222711",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485c6c3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X_fake, y_fake = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for z in tqdm(codes):\n",
    "        image = G(z.reshape(1, latent_dim))\n",
    "        X_fake.append(image.numpy().ravel())\n",
    "        y_fake.append(torch.argmax(lenet(resize(image))).item())\n",
    "\n",
    "X_fake, y_fake = np.array(X_fake), np.array(y_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4a158",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "clf.score(X_fake, y_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2c64c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_fake, y_fake)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22d626",
   "metadata": {},
   "source": [
    "## Exploration de l’espace latent et contrôle de la génération"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323f47aa",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Que se passe-t-il quand la norme de $ z $ devient très grande ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a7f37",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "En utilisant les images synthétiques obtenues précédemment et leurs\n",
    "pseudo-étiquettes, calculez pour chaque classe (chiffre) le barycentre\n",
    "$ m_i $ de celle-ci dans l’espace latent.\n",
    "\n",
    "On définit pour chaque paire de classses $ (i,j) $ la direction\n",
    "$ d_{i,j} = m_j - m_i $. Choisissez deux classes (par exemple 0 et\n",
    "8) et calculez la direction. Calculez différents codes\n",
    "$ z' = z + \\alpha \\cdot d_{i,j} $ pour plusieurs valeurs de\n",
    "$ \\alpha $ et générez les images correspondantes. On choisira un\n",
    "$ z $ qui correspond au chiffre de départ (par exemple 0). Comment\n",
    "l’image se transforme-t-elle lorsque l’on suit la direction choisie ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcc6b7c",
   "metadata": {},
   "source": [
    "## Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f1513",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "barycenter_0 = np.mean(np.array(codes[labels == 0]), axis=0)\n",
    "barycenter_8 = np.mean(np.array(codes[labels == 3]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0f675",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(code2image(barycenter_0)) and plt.show()\n",
    "plt.imshow(code2image(barycenter_8)) and plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cfa7e6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "direction_08 = barycenter_8 - barycenter_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa85f101",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "code0 = codes[990]\n",
    "image0 = code2image(code0)\n",
    "plt.imshow(image0) and plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fed7b3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "for alpha in [0., 0.1, 0.15, 0.17, 0.2, 0.5, 0.8, 1.0, 1.2, 1.5, 1.7, 2.0]:\n",
    "    edit = code0 + alpha * direction_08\n",
    "    plt.imshow(code2image(edit)) and plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9349bcd",
   "metadata": {},
   "source": [
    "Lorsque les codes $ z $ de l’espace latent sont échantillonnés selon\n",
    "une loi normale plutôt qu’une loi uniforme, il est en général considéré\n",
    "préférable d’utiliser une interpolation sphérique plutôt qu’une\n",
    "interpolation linéaire. En effet, pour une gaussienne, les courbes\n",
    "d’iso-probabilité suivent les grands cercles.\n",
    "\n",
    "La fonction `slerp` ci-dessous implémente une telle interpolation\n",
    "selon le grand cercle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63a674",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def slerp(val, low, high):\n",
    "    omega = np.arccos(np.clip(np.dot(low/np.linalg.norm(low), high/np.linalg.norm(high)), -1, 1))\n",
    "    so = np.sin(omega)\n",
    "    if so == 0:\n",
    "        return (1.0-val) * low + val * high # L'Hopital's rule/LERP\n",
    "    return np.sin((1.0-val)*omega) / so * low + np.sin(val*omega) / so * high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b8083",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Appliquez la même technique mais en utilisant une interpolation\n",
    "sphérique plutôt qu’une interpolation linéaire. Visualisez la norme des\n",
    "codes interpolés et comparez là à celle des codes obtenus par\n",
    "interpolation linéaires. Commentez.\n",
    "\n",
    "Visualisez les images interpolées. Qu’en pensez-vous ?"
   ]
  }
 ],
 "metadata": {
  "date": 1650012663.4091585,
  "filename": "TP10-GANLatent.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "title": "Travaux pratiques : espace latent des GAN"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
